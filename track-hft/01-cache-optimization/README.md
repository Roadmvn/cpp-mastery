# Chapitre 01 - Cache Optimization ğŸ”¥

## Pourquoi c'est critique en HFT âš¡

En HFT, chaque **nanoseconde** compte. La difference entre lire depuis le cache L1 et la RAM,
c'est un facteur **~100x**. Un code qui provoque des **cache misses** perd la course avant meme
de commencer. Les meilleurs systemes HFT sont designes autour du cache, pas autour de la logique.

## Hierarchie memoire - Latences reelles ğŸ“Š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CPU Core                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  Registres   ~ 0.3 ns       â”‚  â—„â”€â”€ Acces instantane     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚             â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  Cache L1   32-64 KB        â”‚  â—„â”€â”€ ~1 ns    (4 cycles)  â”‚
â”‚  â”‚  (par core, split I/D)      â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚             â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  Cache L2   256 KB - 1 MB   â”‚  â—„â”€â”€ ~4 ns   (12 cycles)  â”‚
â”‚  â”‚  (par core)                 â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚             â–¼                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  Cache L3   8-64 MB         â”‚  â—„â”€â”€ ~12 ns  (36 cycles)  â”‚
â”‚  â”‚  (partage entre cores)      â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚             â–¼                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  RAM (DRAM)  16-256 GB      â”‚  â—„â”€â”€ ~100 ns (300 cycles) â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Cache Line - L'unite fondamentale ğŸ“¦

Le CPU ne lit **jamais** un seul octet. Il charge toujours une **cache line** de **64 octets**.

```
Adresse memoire:  0x1000  0x1040  0x1080  0x10C0
                    â”‚       â”‚       â”‚       â”‚
                    â–¼       â–¼       â–¼       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
    RAM:         â”‚ 64 B â”‚ 64 B â”‚ 64 B â”‚ 64 B â”‚  ...
                 â””â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          Tu demandes 1 int a 0x1004?
          Le CPU charge TOUTE la ligne 0x1000-0x103F
                    â”‚
                    â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”
    Cache L1:    â”‚ 64 B â”‚  â—„â”€â”€ Cache line complete
                 â””â”€â”€â”€â”€â”€â”€â”˜
```

## Data Locality - Sequentiel vs Random ğŸ¯

```
ACCES SEQUENTIEL (cache-friendly) âœ…          ACCES RANDOM (cache-hostile) âŒ
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”           â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ 1 â”‚ 2 â”‚ 3 â”‚ 4 â”‚ 5 â”‚ 6 â”‚ 7 â”‚ 8 â”‚           â”‚   â”‚   â”‚ 3 â”‚   â”‚   â”‚ 1 â”‚   â”‚ 2 â”‚
â””â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”˜           â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”¬â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”¬â”€â”´â”€â”€â”€â”´â”€â”¬â”€â”˜
  â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                         â”‚           â”‚       â”‚
  â–¼   â–¼   â–¼   â–¼   â–¼   â–¼   â–¼   â–¼                         â–¼           â–¼       â–¼
  1 cache line = 8 ints charges             Chaque acces = potentiel cache miss
  7 hits gratuits apres 1 miss!             Latence x100 a chaque saut
```

## Struct Padding & Alignment ğŸ§±

Le compilateur ajoute du **padding** pour aligner les membres. Ca gaspille de la memoire
et ca peut causer des cache misses supplementaires.

```
MAUVAIS (24 octets avec padding):           BON (16 octets, compact):
struct Bad {                                struct Good {
  char  a;    // 1 byte                      double y;  // 8 bytes
  // 7 bytes PADDING !!                      int    x;  // 4 bytes
  double y;   // 8 bytes                     char   a;  // 1 byte
  int    x;   // 4 bytes                     char   b;  // 1 byte
  char   b;   // 1 byte                      // 2 bytes padding
  // 3 bytes PADDING !!                    };  // Total: 16 bytes
};  // Total: 24 bytes

Layout memoire:                             Layout memoire:
[a|.|.|.|.|.|.|.][y y y y y y y y]          [y y y y y y y y][x x x x|a|b|.|.]
[x x x x|b|.|.|.]
     3 lignes potentielles                       2 lignes max = plus compact
```

## alignas - Forcer l'alignement ğŸ”§

```cpp
// Force la struct a etre alignee sur une cache line
struct alignas(64) MarketData {
    double price;      // 8
    int    quantity;    // 4
    int    order_id;   // 4
    char   side;       // 1
    // padding auto    // 43 bytes
};  // Total: exactement 64 bytes = 1 cache line

// Empeche le false sharing entre threads
struct alignas(64) PerThreadCounter {
    std::atomic<long> count{0};
    // Chaque thread a sa propre cache line
};
```

## Prefetching ğŸš€

Dire au CPU de charger une donnee en cache **avant** d'en avoir besoin.

```cpp
// Le CPU charge data[i+16] pendant qu'on traite data[i]
for (int i = 0; i < N; i++) {
    __builtin_prefetch(&data[i + 16], 0, 3);  // read, haute localite
    process(data[i]);
}
```

## Exemple concret - Impact mesurable ğŸ“ˆ

```cpp
#include <iostream>
#include <vector>
#include <chrono>
#include <numeric>

struct alignas(64) CacheFriendlyOrder {
    double price;
    int quantity;
    int id;
};

struct CacheHostileOrder {
    char padding1[60];  // pousse au-dela de la cache line
    double price;
    char padding2[60];
    int quantity;
    char padding3[60];
    int id;
};

int main() {
    constexpr int N = 1'000'000;

    // Test cache-friendly
    std::vector<CacheFriendlyOrder> good(N);
    for (int i = 0; i < N; i++) good[i] = {100.0 + i, i, i};

    auto start = std::chrono::high_resolution_clock::now();
    double sum = 0;
    for (int i = 0; i < N; i++) sum += good[i].price;
    auto end = std::chrono::high_resolution_clock::now();
    auto good_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();

    // Test cache-hostile
    std::vector<CacheHostileOrder> bad(N);
    for (int i = 0; i < N; i++) bad[i] = {{}, 100.0 + i, {}, i, {}, i};

    start = std::chrono::high_resolution_clock::now();
    sum = 0;
    for (int i = 0; i < N; i++) sum += bad[i].price;
    end = std::chrono::high_resolution_clock::now();
    auto bad_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();

    std::cout << "Cache-friendly: " << good_time << " us\n";
    std::cout << "Cache-hostile:  " << bad_time  << " us\n";
    std::cout << "Ratio:          " << (double)bad_time / good_time << "x plus lent\n";
}
```

## Checkpoint âœ…

Avant de passer au chapitre suivant, tu dois savoir :
- [ ] Pourquoi le CPU charge des cache lines de 64 bytes et pas des bytes individuels
- [ ] La difference de latence entre L1, L2, L3 et RAM
- [ ] Comment organiser une struct pour minimiser le padding
- [ ] Ce que fait `alignas(64)` et pourquoi c'est utile en HFT
- [ ] Pourquoi l'acces sequentiel est 10-100x plus rapide que l'acces random

---
Compilation : `g++ -std=c++17 -O2 -o cache exercise.cpp && ./cache`
