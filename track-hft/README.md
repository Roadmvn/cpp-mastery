# Track HFT : Low-Latency C++

**Deviens le dev qui fait tourner les marchÃ©s financiers.**

Le trading haute frÃ©quence (HFT), c'est lÃ  oÃ¹ chaque **nanoseconde** compte. Les firmes comme Citadel, Jump Trading, Jane Street et Tower Research utilisent C++ parce qu'aucun autre langage ne donne ce niveau de contrÃ´le sur le hardware. Pas de garbage collector, pas de runtime, pas de surprises. Juste toi, le CPU et la mÃ©moire.

Dans ce track, tu vas apprendre Ã  Ã©crire du code C++ qui rivalise avec ce qui tourne en production dans les plus grosses firmes de trading du monde.

---

## Ce que tu vas maÃ®triser

- Optimisation cache L1/L2/L3 et data locality
- Allocation mÃ©moire custom sans fragmentation
- Structures lock-free pour le multithreading sans mutex
- Networking TCP/UDP ultra-rapide
- Programmation SIMD (vectorisation CPU)
- Mesure et rÃ©duction de la latence au niveau nanoseconde
- Construction d'un matching engine complet

---

## PrÃ©requis

Tu **dois** avoir complÃ©tÃ© ces sections avant de commencer :

| Section | Pourquoi |
|---------|----------|
| [01-foundations](../01-foundations) | Syntaxe C++ de base |
| [02-memory-and-arrays](../02-memory-and-arrays) | Pointeurs, mÃ©moire dynamique, rÃ©fÃ©rences |
| [03-oop](../03-oop) | Classes, hÃ©ritage, smart pointers, RAII |
| [04-stl-mastery](../04-stl-mastery) | Containers STL, iterators, algorithmes |

Si tu n'as pas fait ces sections, retourne au [README principal](../README.md). Pas de raccourcis.

---

## Roadmap dÃ©taillÃ©e

### 01 â€” Cache Optimization
[`01-cache-optimization/`](01-cache-optimization/)

Ton CPU est rapide. Ta RAM est lente. Le cache est le pont entre les deux, et la plupart des devs l'ignorent complÃ¨tement. Tu vas apprendre comment structurer tes donnÃ©es pour que le CPU les trouve **toujours** dans le cache.

**Concepts clÃ©s :**
- HiÃ©rarchie mÃ©moire : registres  L1  L2  L3  RAM
- Cache lines (64 bytes), cache hits vs cache misses
- Data locality : spatial et temporal
- Structure of Arrays (SoA) vs Array of Structures (AoS)
- False sharing et padding
- `__builtin_prefetch`, alignement mÃ©moire

**AprÃ¨s ce chapitre :** Tu sauras organiser tes donnÃ©es pour des accÃ¨s mÃ©moire 10x plus rapides. Tu comprendras pourquoi un `vector<int>` Ã©crase un `list<int>` en performance.

---

### 02 â€” Memory Pools & Allocators ğŸŠ
[`02-memory-pools-allocators/`](02-memory-pools-allocators/)

`new` et `delete` sont trop lents pour le HFT. Chaque allocation passe par l'OS, et Ã§a prend des **microsecondes**. En HFT, on prÃ©-alloue tout. Tu vas construire tes propres allocateurs.

**Concepts clÃ©s :**
- ProblÃ¨me de `malloc`/`new` : fragmentation, syscalls, locks
- Pool allocators : prÃ©-allocation de blocs fixes
- Arena allocators : allocation linÃ©aire ultra-rapide
- Slab allocators : pools par taille d'objet
- `std::pmr` (Polymorphic Memory Resources)
- Placement new

**AprÃ¨s ce chapitre :** Tu sauras Ã©crire un allocateur custom qui Ã©limine les allocations dynamiques en hot path. ZÃ©ro appel Ã  l'OS pendant l'exÃ©cution critique.

---

### 03 â€” Lock-Free Data Structures ğŸ”“
[`03-lock-free-structures/`](03-lock-free-structures/)

Les mutex tuent la performance. Quand un thread attend un lock, il dort. En HFT, personne ne dort. Tu vas apprendre Ã  Ã©crire des structures de donnÃ©es qui fonctionnent sans aucun lock.

**Concepts clÃ©s :**
- Pourquoi les mutex sont interdits en hot path
- `std::atomic`, memory ordering (relaxed, acquire, release, seq_cst)
- Compare-And-Swap (CAS) : la brique de base du lock-free
- SPSC queue (Single Producer Single Consumer) lock-free
- MPSC queue (Multiple Producer Single Consumer)
- ABA problem et solutions
- Hazard pointers, epoch-based reclamation

**AprÃ¨s ce chapitre :** Tu sauras construire une queue lock-free SPSC avec une latence de quelques nanosecondes. C'est la structure la plus utilisÃ©e en HFT pour passer des messages entre threads.

---

### 04 â€” Networking : TCP & UDP
[`04-networking-tcp-udp/`](04-networking-tcp-udp/)

Les marchÃ©s envoient des donnÃ©es via le rÃ©seau. Tu dois les recevoir le plus vite possible. TCP pour les ordres (fiabilitÃ©), UDP multicast pour les market data (vitesse). Tu vas coder des deux cÃ´tÃ©s.

**Concepts clÃ©s :**
- Sockets POSIX : `socket()`, `bind()`, `listen()`, `accept()`
- TCP : connexion fiable, Nagle's algorithm (et pourquoi le dÃ©sactiver)
- UDP : datagrams, multicast, broadcast
- `epoll` / `kqueue` : I/O multiplexing sans threads
- Kernel bypass : concepts de DPDK et Solarflare OpenOnload
- SÃ©rialisation zero-copy avec `reinterpret_cast`

**AprÃ¨s ce chapitre :** Tu sauras Ã©crire un serveur TCP et un rÃ©cepteur UDP multicast optimisÃ©s. Tu comprendras comment les feeds de marchÃ© arrivent et comment les traiter avec une latence minimale.

---

### 05 â€” Multithreading & Atomics
[`05-multithreading-atomics/`](05-multithreading-atomics/)

Le HFT utilise le multithreading, mais pas comme une app web. Chaque thread est pinnÃ© Ã  un core CPU. Pas de context switching, pas de migrations. Tu vas apprendre le threading de prÃ©cision.

**Concepts clÃ©s :**
- `std::thread`, `std::jthread`
- Thread affinity : `pthread_setaffinity_np`, CPU pinning
- Spinlocks vs mutex : quand utiliser quoi
- Thread-local storage (`thread_local`)
- Busy-waiting : pourquoi c'est acceptable en HFT
- Isoler les cores CPU (`isolcpus`, `taskset`)
- Pipeline threading : chaque thread = une Ã©tape du pipeline

**AprÃ¨s ce chapitre :** Tu sauras architecturer une application multi-threadÃ©e oÃ¹ chaque thread est dÃ©diÃ© Ã  une tÃ¢che prÃ©cise sur un core isolÃ©, sans contention.

---

### 06 â€” SIMD & Intrinsics ğŸš„
[`06-simd-intrinsics/`](06-simd-intrinsics/)

Ton CPU peut traiter 4, 8 ou mÃªme 16 donnÃ©es en **une seule instruction**. C'est le SIMD (Single Instruction Multiple Data). Les firmes HFT l'utilisent pour parser les market data Ã  la vitesse du hardware.

**Concepts clÃ©s :**
- SSE, SSE2, AVX, AVX2, AVX-512
- Types vectoriels : `__m128`, `__m256`, `__m512`
- Intrinsics : `_mm256_add_ps`, `_mm256_cmp_pd`, etc.
- Auto-vectorisation du compilateur et ses limites
- SIMD pour parser du texte (FIX protocol)
- SIMD pour les calculs de prix et risk

**AprÃ¨s ce chapitre :** Tu sauras utiliser les instructions SIMD pour traiter des donnÃ©es 4-8x plus vite qu'en code scalaire. Tu comprendras quand le compilateur vectorise automatiquement et quand il faut le faire Ã  la main.

---

### 07 â€” Order Book Engine
[`07-order-book-engine/`](07-order-book-engine/)

L'order book, c'est le coeur de tout exchange. Buy orders d'un cÃ´tÃ©, sell orders de l'autre, et un matching engine au milieu qui croise les ordres. Tu vas en construire un de A Ã  Z.

**Concepts clÃ©s :**
- Structure d'un order book : bids, asks, price levels
- Types d'ordres : limit, market, cancel, modify
- Matching algorithms : price-time priority (FIFO)
- Structures de donnÃ©es optimales : `std::map` vs intrusive lists
- Order indexing par ID pour cancel/modify en O(1)
- Message parsing (simulated FIX/ITCH)

**AprÃ¨s ce chapitre :** Tu auras un order book fonctionnel qui gÃ¨re les ordres limit/market avec matching price-time priority. La base de ton projet final.

---

### 08 â€” Latency Measurement
[`08-latency-measurement/`](08-latency-measurement/)

"Ce qui ne se mesure pas ne s'amÃ©liore pas." En HFT, tu mesures tout en nanosecondes. Tu vas apprendre Ã  profiler ton code avec une prÃ©cision chirurgicale.

**Concepts clÃ©s :**
- `std::chrono::high_resolution_clock` et ses limites
- `rdtsc` / `rdtscp` : lire le compteur CPU directement
- Percentiles : p50, p99, p99.9 (la moyenne ment)
- Microbenchmarking avec Google Benchmark
- `perf stat`, `perf record`, flamegraphs
- Cache profiling : `perf` events (L1-dcache-load-misses)
- Jitter : sources et mitigation (NUMA, CPU freq, interrupts)

**AprÃ¨s ce chapitre :** Tu sauras mesurer la latence de n'importe quel code au nanoseconde prÃ¨s, identifier les bottlenecks et les Ã©liminer systÃ©matiquement.

---

## Projet final : Matching Engine
[`projects/matching-engine/`](projects/matching-engine/)

Tout ce que tu as appris converge ici. Tu vas construire un **matching engine complet** avec :

- Order book multi-symboles
- Matching price-time priority
- Queue SPSC lock-free entre les composants
- Memory pool custom pour zero-allocation en hot path
- RÃ©ception des ordres via TCP
- Market data broadcast via UDP multicast
- Mesure de latence tick-to-trade < 10 microsecondes

---

## Architecture d'un systÃ¨me HFT

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    EXCHANGE / MARCHE                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ UDP Multicast                    â–² TCP
                â”‚ (Market Data)                    â”‚ (Orders)
                â–¼                                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚   FEED HANDLER    â”‚                          â”‚
    â”‚                   â”‚                          â”‚
    â”‚ Parse ITCH/FIX    â”‚                          â”‚
    â”‚ Normalize data    â”‚                          â”‚
    â”‚ SIMD parsing      â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
             â”‚ SPSC Queue                          â”‚
             â”‚ (lock-free)                         â”‚
             â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚   ORDER BOOK      â”‚â”€â”€â”€>â”‚   STRATEGY   â”‚      â”‚
    â”‚                   â”‚    â”‚   ENGINE     â”‚      â”‚
    â”‚ Update bids/asks  â”‚    â”‚              â”‚      â”‚
    â”‚ Price levels      â”‚    â”‚ Signal gen   â”‚      â”‚
    â”‚ BBO tracking      â”‚    â”‚ Alpha calc   â”‚      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                                    â”‚              â”‚
                                    â–¼              â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                             â”‚     RISK     â”‚      â”‚
                             â”‚    CHECK     â”‚      â”‚
                             â”‚              â”‚      â”‚
                             â”‚ Position lim â”‚      â”‚
                             â”‚ Order size   â”‚      â”‚
                             â”‚ Rate limit   â”‚      â”‚
                             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                                    â”‚              â”‚
                                    â–¼              â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                             â”‚  ORDER       â”‚â”€â”€â”€â”€â”€â”€â”˜
                             â”‚  GATEWAY     â”‚
                             â”‚              â”‚
                             â”‚ Serialize    â”‚
                             â”‚ Send to exch â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     Latence totale tick-to-trade : < 10 microsecondes
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

Chaque composant tourne sur son propre core CPU isolÃ©, communique via des queues lock-free, et n'alloue **aucune mÃ©moire** en hot path.

---

## Ressources recommandÃ©es ğŸ“š

### Livres
- **"C++ High Performance"** â€” Bjorn Andrist & Viktor Sehr â€” Optimisation moderne C++
- **"The Art of Writing Efficient Programs"** â€” Fedor Pikus â€” Performance-oriented C++
- **"Is Parallel Programming Hard, And, If So, What Can You Do About It?"** â€” Paul McKenney â€” Lock-free et concurrence (gratuit en PDF)
- **"Computer Systems: A Programmer's Perspective"** â€” Bryant & O'Hallaron â€” Comprendre le hardware

### Blogs et sites
- [Mechanical Sympathy](https://mechanical-sympathy.blogspot.com/) â€” Martin Thompson, lÃ©gende du low-latency
- [Brendan Gregg's Blog](https://www.brendangregg.com/) â€” Profiling et performance systems
- [CppCon YouTube](https://www.youtube.com/user/CppCon) â€” Talks pointus sur la performance C++
- [Agner Fog's Manuals](https://www.agner.org/optimize/) â€” Bibles de l'optimisation x86

### Tools
- **perf** â€” Profiler Linux intÃ©grÃ© au kernel
- **Google Benchmark** â€” Micro-benchmarking framework
- **Compiler Explorer (godbolt.org)** â€” Voir l'assembleur gÃ©nÃ©rÃ© par ton code
- **Valgrind / Cachegrind** â€” Analyse cache et mÃ©moire

---

## Let's trade

```
g++ -std=c++17 -O2 -march=native -o cache 01-cache-optimization/exercise.cpp && ./cache
```

Le flag `-O2` active les optimisations du compilateur. `-march=native` cible ton CPU exact. C'est comme Ã§a qu'on compile en HFT.
