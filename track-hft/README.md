# Track HFT : Low-Latency C++ 

**Deviens le dev qui fait tourner les march√©s financiers.**

Le trading haute fr√©quence (HFT), c'est l√† o√π chaque **nanoseconde** compte. Les firmes comme Citadel, Jump Trading, Jane Street et Tower Research utilisent C++ parce qu'aucun autre langage ne donne ce niveau de contr√¥le sur le hardware. Pas de garbage collector, pas de runtime, pas de surprises. Juste toi, le CPU et la m√©moire.

Dans ce track, tu vas apprendre √† √©crire du code C++ qui rivalise avec ce qui tourne en production dans les plus grosses firmes de trading du monde.

---

## Ce que tu vas ma√Ætriser 

- Optimisation cache L1/L2/L3 et data locality
- Allocation m√©moire custom sans fragmentation
- Structures lock-free pour le multithreading sans mutex
- Networking TCP/UDP ultra-rapide
- Programmation SIMD (vectorisation CPU)
- Mesure et r√©duction de la latence au niveau nanoseconde
- Construction d'un matching engine complet

---

## Pr√©requis 

Tu **dois** avoir compl√©t√© ces sections avant de commencer :

| Section | Pourquoi |
|---------|----------|
| [01-foundations](../01-foundations) | Syntaxe C++ de base |
| [02-memory-and-arrays](../02-memory-and-arrays) | Pointeurs, m√©moire dynamique, r√©f√©rences |
| [03-oop](../03-oop) | Classes, h√©ritage, smart pointers, RAII |
| [04-stl-mastery](../04-stl-mastery) | Containers STL, iterators, algorithmes |

Si tu n'as pas fait ces sections, retourne au [README principal](../README.md). Pas de raccourcis.

---

## Roadmap d√©taill√©e 

### 01 ‚Äî Cache Optimization 
[`01-cache-optimization/`](01-cache-optimization/)

Ton CPU est rapide. Ta RAM est lente. Le cache est le pont entre les deux, et la plupart des devs l'ignorent compl√®tement. Tu vas apprendre comment structurer tes donn√©es pour que le CPU les trouve **toujours** dans le cache.

**Concepts cl√©s :**
- Hi√©rarchie m√©moire : registres  L1  L2  L3  RAM
- Cache lines (64 bytes), cache hits vs cache misses
- Data locality : spatial et temporal
- Structure of Arrays (SoA) vs Array of Structures (AoS)
- False sharing et padding
- `__builtin_prefetch`, alignement m√©moire

**Apr√®s ce chapitre :** Tu sauras organiser tes donn√©es pour des acc√®s m√©moire 10x plus rapides. Tu comprendras pourquoi un `vector<int>` √©crase un `list<int>` en performance.

---

### 02 ‚Äî Memory Pools & Allocators üèä
[`02-memory-pools-allocators/`](02-memory-pools-allocators/)

`new` et `delete` sont trop lents pour le HFT. Chaque allocation passe par l'OS, et √ßa prend des **microsecondes**. En HFT, on pr√©-alloue tout. Tu vas construire tes propres allocateurs.

**Concepts cl√©s :**
- Probl√®me de `malloc`/`new` : fragmentation, syscalls, locks
- Pool allocators : pr√©-allocation de blocs fixes
- Arena allocators : allocation lin√©aire ultra-rapide
- Slab allocators : pools par taille d'objet
- `std::pmr` (Polymorphic Memory Resources)
- Placement new

**Apr√®s ce chapitre :** Tu sauras √©crire un allocateur custom qui √©limine les allocations dynamiques en hot path. Z√©ro appel √† l'OS pendant l'ex√©cution critique.

---

### 03 ‚Äî Lock-Free Data Structures üîì
[`03-lock-free-structures/`](03-lock-free-structures/)

Les mutex tuent la performance. Quand un thread attend un lock, il dort. En HFT, personne ne dort. Tu vas apprendre √† √©crire des structures de donn√©es qui fonctionnent sans aucun lock.

**Concepts cl√©s :**
- Pourquoi les mutex sont interdits en hot path
- `std::atomic`, memory ordering (relaxed, acquire, release, seq_cst)
- Compare-And-Swap (CAS) : la brique de base du lock-free
- SPSC queue (Single Producer Single Consumer) lock-free
- MPSC queue (Multiple Producer Single Consumer)
- ABA problem et solutions
- Hazard pointers, epoch-based reclamation

**Apr√®s ce chapitre :** Tu sauras construire une queue lock-free SPSC avec une latence de quelques nanosecondes. C'est la structure la plus utilis√©e en HFT pour passer des messages entre threads.

---

### 04 ‚Äî Networking : TCP & UDP 
[`04-networking-tcp-udp/`](04-networking-tcp-udp/)

Les march√©s envoient des donn√©es via le r√©seau. Tu dois les recevoir le plus vite possible. TCP pour les ordres (fiabilit√©), UDP multicast pour les market data (vitesse). Tu vas coder des deux c√¥t√©s.

**Concepts cl√©s :**
- Sockets POSIX : `socket()`, `bind()`, `listen()`, `accept()`
- TCP : connexion fiable, Nagle's algorithm (et pourquoi le d√©sactiver)
- UDP : datagrams, multicast, broadcast
- `epoll` / `kqueue` : I/O multiplexing sans threads
- Kernel bypass : concepts de DPDK et Solarflare OpenOnload
- S√©rialisation zero-copy avec `reinterpret_cast`

**Apr√®s ce chapitre :** Tu sauras √©crire un serveur TCP et un r√©cepteur UDP multicast optimis√©s. Tu comprendras comment les feeds de march√© arrivent et comment les traiter avec une latence minimale.

---

### 05 ‚Äî Multithreading & Atomics 
[`05-multithreading-atomics/`](05-multithreading-atomics/)

Le HFT utilise le multithreading, mais pas comme une app web. Chaque thread est pinn√© √† un core CPU. Pas de context switching, pas de migrations. Tu vas apprendre le threading de pr√©cision.

**Concepts cl√©s :**
- `std::thread`, `std::jthread`
- Thread affinity : `pthread_setaffinity_np`, CPU pinning
- Spinlocks vs mutex : quand utiliser quoi
- Thread-local storage (`thread_local`)
- Busy-waiting : pourquoi c'est acceptable en HFT
- Isoler les cores CPU (`isolcpus`, `taskset`)
- Pipeline threading : chaque thread = une √©tape du pipeline

**Apr√®s ce chapitre :** Tu sauras architecturer une application multi-thread√©e o√π chaque thread est d√©di√© √† une t√¢che pr√©cise sur un core isol√©, sans contention.

---

### 06 ‚Äî SIMD & Intrinsics üöÑ
[`06-simd-intrinsics/`](06-simd-intrinsics/)

Ton CPU peut traiter 4, 8 ou m√™me 16 donn√©es en **une seule instruction**. C'est le SIMD (Single Instruction Multiple Data). Les firmes HFT l'utilisent pour parser les market data √† la vitesse du hardware.

**Concepts cl√©s :**
- SSE, SSE2, AVX, AVX2, AVX-512
- Types vectoriels : `__m128`, `__m256`, `__m512`
- Intrinsics : `_mm256_add_ps`, `_mm256_cmp_pd`, etc.
- Auto-vectorisation du compilateur et ses limites
- SIMD pour parser du texte (FIX protocol)
- SIMD pour les calculs de prix et risk

**Apr√®s ce chapitre :** Tu sauras utiliser les instructions SIMD pour traiter des donn√©es 4-8x plus vite qu'en code scalaire. Tu comprendras quand le compilateur vectorise automatiquement et quand il faut le faire √† la main.

---

### 07 ‚Äî Order Book Engine 
[`07-order-book-engine/`](07-order-book-engine/)

L'order book, c'est le coeur de tout exchange. Buy orders d'un c√¥t√©, sell orders de l'autre, et un matching engine au milieu qui croise les ordres. Tu vas en construire un de A √† Z.

**Concepts cl√©s :**
- Structure d'un order book : bids, asks, price levels
- Types d'ordres : limit, market, cancel, modify
- Matching algorithms : price-time priority (FIFO)
- Structures de donn√©es optimales : `std::map` vs intrusive lists
- Order indexing par ID pour cancel/modify en O(1)
- Message parsing (simulated FIX/ITCH)

**Apr√®s ce chapitre :** Tu auras un order book fonctionnel qui g√®re les ordres limit/market avec matching price-time priority. La base de ton projet final.

---

### 08 ‚Äî Latency Measurement 
[`08-latency-measurement/`](08-latency-measurement/)

"Ce qui ne se mesure pas ne s'am√©liore pas." En HFT, tu mesures tout en nanosecondes. Tu vas apprendre √† profiler ton code avec une pr√©cision chirurgicale.

**Concepts cl√©s :**
- `std::chrono::high_resolution_clock` et ses limites
- `rdtsc` / `rdtscp` : lire le compteur CPU directement
- Percentiles : p50, p99, p99.9 (la moyenne ment)
- Microbenchmarking avec Google Benchmark
- `perf stat`, `perf record`, flamegraphs
- Cache profiling : `perf` events (L1-dcache-load-misses)
- Jitter : sources et mitigation (NUMA, CPU freq, interrupts)

**Apr√®s ce chapitre :** Tu sauras mesurer la latence de n'importe quel code au nanoseconde pr√®s, identifier les bottlenecks et les √©liminer syst√©matiquement.

---

## Projet final : Matching Engine 
[`projects/matching-engine/`](projects/matching-engine/)

Tout ce que tu as appris converge ici. Tu vas construire un **matching engine complet** avec :

- Order book multi-symboles
- Matching price-time priority
- Queue SPSC lock-free entre les composants
- Memory pool custom pour zero-allocation en hot path
- R√©ception des ordres via TCP
- Market data broadcast via UDP multicast
- Mesure de latence tick-to-trade < 10 microsecondes

---

## Architecture d'un syst√®me HFT üèõ

```
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                    EXCHANGE / MARCHE                            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ UDP Multicast                    ‚ñ≤ TCP
                ‚îÇ (Market Data)                    ‚îÇ (Orders)
                ‚ñº                                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
    ‚îÇ   FEED HANDLER    ‚îÇ                          ‚îÇ
    ‚îÇ                   ‚îÇ                          ‚îÇ
    ‚îÇ Parse ITCH/FIX    ‚îÇ                          ‚îÇ
    ‚îÇ Normalize data    ‚îÇ                          ‚îÇ
    ‚îÇ SIMD parsing      ‚îÇ                          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
             ‚îÇ SPSC Queue                          ‚îÇ
             ‚îÇ (lock-free)                         ‚îÇ
             ‚ñº                                     ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
    ‚îÇ   ORDER BOOK      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÇ   STRATEGY   ‚îÇ      ‚îÇ
    ‚îÇ                   ‚îÇ    ‚îÇ   ENGINE     ‚îÇ      ‚îÇ
    ‚îÇ Update bids/asks  ‚îÇ    ‚îÇ              ‚îÇ      ‚îÇ
    ‚îÇ Price levels      ‚îÇ    ‚îÇ Signal gen   ‚îÇ      ‚îÇ
    ‚îÇ BBO tracking      ‚îÇ    ‚îÇ Alpha calc   ‚îÇ      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                                    ‚îÇ              ‚îÇ
                                    ‚ñº              ‚îÇ
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
                             ‚îÇ    RISK       ‚îÇ      ‚îÇ
                             ‚îÇ   CHECK      ‚îÇ      ‚îÇ
                             ‚îÇ              ‚îÇ      ‚îÇ
                             ‚îÇ Position lim ‚îÇ      ‚îÇ
                             ‚îÇ Order size   ‚îÇ      ‚îÇ
                             ‚îÇ Rate limit   ‚îÇ      ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                                    ‚îÇ              ‚îÇ
                                    ‚ñº              ‚îÇ
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
                             ‚îÇ  ORDER       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ  GATEWAY     ‚îÇ
                             ‚îÇ              ‚îÇ
                             ‚îÇ Serialize    ‚îÇ
                             ‚îÇ Send to exch ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     Latence totale tick-to-trade : < 10 microsecondes
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

Chaque composant tourne sur son propre core CPU isol√©, communique via des queues lock-free, et n'alloue **aucune m√©moire** en hot path.

---

## Ressources recommand√©es üìö

### Livres
- **"C++ High Performance"** ‚Äî Bjorn Andrist & Viktor Sehr ‚Äî Optimisation moderne C++
- **"The Art of Writing Efficient Programs"** ‚Äî Fedor Pikus ‚Äî Performance-oriented C++
- **"Is Parallel Programming Hard, And, If So, What Can You Do About It?"** ‚Äî Paul McKenney ‚Äî Lock-free et concurrence (gratuit en PDF)
- **"Computer Systems: A Programmer's Perspective"** ‚Äî Bryant & O'Hallaron ‚Äî Comprendre le hardware

### Blogs et sites
- [Mechanical Sympathy](https://mechanical-sympathy.blogspot.com/) ‚Äî Martin Thompson, l√©gende du low-latency
- [Brendan Gregg's Blog](https://www.brendangregg.com/) ‚Äî Profiling et performance systems
- [CppCon YouTube](https://www.youtube.com/user/CppCon) ‚Äî Talks pointus sur la performance C++
- [Agner Fog's Manuals](https://www.agner.org/optimize/) ‚Äî Bibles de l'optimisation x86

### Tools
- **perf** ‚Äî Profiler Linux int√©gr√© au kernel
- **Google Benchmark** ‚Äî Micro-benchmarking framework
- **Compiler Explorer (godbolt.org)** ‚Äî Voir l'assembleur g√©n√©r√© par ton code
- **Valgrind / Cachegrind** ‚Äî Analyse cache et m√©moire

---

## Let's trade 

```
g++ -std=c++17 -O2 -march=native -o cache 01-cache-optimization/exercise.cpp && ./cache
```

Le flag `-O2` active les optimisations du compilateur. `-march=native` cible ton CPU exact. C'est comme √ßa qu'on compile en HFT.
